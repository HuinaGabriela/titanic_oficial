Kaggle Â· CompetiÃ§Ã£o de aprendizado de mÃ¡quina a partir de desastres.

# ğŸ›³ï¸ Titanic - Machine Learning from Disaster

Este projeto Ã© uma soluÃ§Ã£o para o clÃ¡ssico desafio do [Kaggle Titanic](https://www.kaggle.com/competitions/titanic) usando machine learning para prever quais passageiros sobreviveram ao naufrÃ¡gio com base em dados disponÃ­veis.

## ğŸ“‚ Estrutura do Projeto
```
titanic_oficial/
â”‚
â”œâ”€â”€ data/ # Dados crus (train.csv, test.csv)
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ init.py # Torna src um pacote
â”‚ â””â”€â”€ data_preprocessing.py # FunÃ§Ãµes de prÃ©-processamento
â”œâ”€â”€ models/ # Modelos treinados (.pkl/.joblib)
â”œâ”€â”€ main.py # Pipeline principal de treino e submissÃ£o
â”œâ”€â”€ requirements.txt # Bibliotecas necessÃ¡rias
â”œâ”€â”€ submission_xgboost_tuned.csv # SubmissÃ£o para o Kaggle
â””â”€â”€ README.md
```
## âš™ï¸ Tecnologias Utilizadas
- Python 3.10
- Pandas, NumPy
- Seaborn, Matplotlib
- Scikit-learn
- XGBoost
- Joblib

## ğŸ“Š Abordagem

1. **PrÃ©-processamento de dados** (`src/data_preprocessing.py`):
   - Preenchimento de valores ausentes
   - ExtraÃ§Ã£o de tÃ­tulos dos nomes (`Mr`, `Mrs`, etc.)
   - CriaÃ§Ã£o de nova feature: `FamilySize`
   - One-hot encoding (`get_dummies`)
   - Alinhamento entre treino e teste

2. **Treinamento do modelo**:
   - Uso de `XGBClassifier`
   - ValidaÃ§Ã£o cruzada com `StratifiedKFold`
   - Busca de hiperparÃ¢metros com `RandomizedSearchCV`

3. **VisualizaÃ§Ãµes**:
   - GrÃ¡ficos com `seaborn` para anÃ¡lise de sobrevivÃªncia por variÃ¡veis como sexo, classe, tÃ­tulo, etc.
   - GrÃ¡fico de importÃ¢ncia de features baseado no XGBoost

4. **ExportaÃ§Ã£o**:
   - GeraÃ§Ã£o de `submission.csv`
   - Salvamento do modelo final com `joblib`

## ğŸ“ˆ Resultados
- Modelo final: `XGBoost`
- MÃ©trica de avaliaÃ§Ã£o: `accuracy` com validaÃ§Ã£o cruzada
- Arquivo gerado: `submission_xgboost_tuned.csv`
- Score no Kaggle: Melhor acurÃ¡cia (validaÃ§Ã£o cruzada):~0.8507


